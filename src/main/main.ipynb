{
 "cells": [
  {
   "cell_type": "code",
   "id": "7af0c266067e769f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T19:46:16.995728Z",
     "start_time": "2024-08-14T19:45:47.236573Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import load_model\n",
    "from keras.utils.version_utils import callbacks\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "af84c3e2a18a5c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T19:46:19.889417Z",
     "start_time": "2024-08-14T19:46:16.995728Z"
    }
   },
   "source": [
    "from src.utility import InstrumentDataset\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\" Load and preprocess data \"\"\"\n",
    "    x, y, classes = InstrumentDataset.read_data('../../Dataset', MERGE_FACTOR, TIME_FRAME,\n",
    "                                                folder='../../Models/splits/train')\n",
    "    # x, y, classes = InstrumentDataset.read_data('../../archive/NavaDataset/Data/', MERGE_FACTOR, TIME_FRAME)\n",
    "    print(np.array(x).shape)\n",
    "    X = np.array(x)[..., np.newaxis]  # Add an extra dimension for the channels\n",
    "    print(f'The shape of X is {X.shape}')\n",
    "    print(f'The shape of y is {y.shape}')\n",
    "    return X, y, classes"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "4f7929b59a781ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T19:57:57.734061Z",
     "start_time": "2024-08-14T19:46:19.889417Z"
    }
   },
   "source": [
    "TIME_FRAME = 1\n",
    "MERGE_FACTOR = 5\n",
    "x, y, classes = load_data()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tar', 'Kamancheh', 'Santur', 'Setar', 'Ney']\n",
      "Tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7646/7646 [01:34<00:00, 80.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamancheh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8039/8039 [01:40<00:00, 79.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7856/7856 [01:50<00:00, 71.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9901/12132 [02:27<00:33, 67.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8134/8134 [02:03<00:00, 65.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "Class: 0\n",
      "Class Indices: [   0    1    2 ... 5873 5874 5875]\n",
      "Class Indices Type: <class 'numpy.ndarray'>\n",
      "Class Indices Dtype: int64\n",
      "x Shape: (33813, 216, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\PycharmProjects\\Thesis\\.venv\\lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=216\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "Class Indices: [ 5876  5877  5878 ... 12490 12491 12492]\n",
      "Class Indices Type: <class 'numpy.ndarray'>\n",
      "Class Indices Dtype: int64\n",
      "x Shape: (33813, 216, 64)\n",
      "Class: 2\n",
      "Class Indices: [12493 12494 12495 ... 18679 18680 18681]\n",
      "Class Indices Type: <class 'numpy.ndarray'>\n",
      "Class Indices Dtype: int64\n",
      "x Shape: (33813, 216, 64)\n",
      "Class: 3\n",
      "Class Indices: [18682 18683 18684 ... 27319 27320 27321]\n",
      "Class Indices Type: <class 'numpy.ndarray'>\n",
      "Class Indices Dtype: int64\n",
      "x Shape: (33813, 216, 64)\n",
      "Class: 4\n",
      "Class Indices: [27322 27323 27324 ... 33810 33811 33812]\n",
      "Class Indices Type: <class 'numpy.ndarray'>\n",
      "Class Indices Dtype: int64\n",
      "x Shape: (33813, 216, 64)\n",
      "[[-80.         -80.         -80.         ... -80.         -80.\n",
      "  -80.        ]\n",
      " [-80.         -80.         -80.         ... -80.         -80.\n",
      "  -80.        ]\n",
      " [-80.         -80.         -80.         ... -80.         -80.\n",
      "  -80.        ]\n",
      " ...\n",
      " [-26.5782299  -22.51656914 -22.23013115 ... -37.69318008 -37.37367249\n",
      "  -40.00380325]\n",
      " [-25.92939377 -22.3690567  -22.94311714 ... -37.42435074 -37.79062653\n",
      "  -39.68937302]\n",
      " [-26.2985096  -22.8375988  -23.22224236 ... -38.89030838 -38.96084976\n",
      "  -39.2273674 ]] 43200\n",
      "(43200, 216, 64)\n",
      "The shape of X is (43200, 216, 64, 1)\n",
      "The shape of y is (43200, 5)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a81818250b7300b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T19:57:57.749480Z",
     "start_time": "2024-08-14T19:57:57.736059Z"
    }
   },
   "source": [
    "def get_encoder(x_train, y_train, x_test, y_test, batch_size, num_epochs, fold_no, input_shape, early_stopping):\n",
    "    model_checkpoint_path = f'model_best_encoder_{fold_no}.keras'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=model_checkpoint_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "    temperature = 0.05\n",
    "\n",
    "    layer_sizes = [512, 256, 128, 64]\n",
    "\n",
    "    encoder = create_encoder(layer_sizes, input_shape)\n",
    "\n",
    "    encoder_with_projection_head = add_projection_head(encoder, input_shape)\n",
    "    encoder_with_projection_head.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=SupervisedContrastiveLoss(temperature),\n",
    "    )\n",
    "\n",
    "    encoder_with_projection_head.summary()\n",
    "\n",
    "    encoder_with_projection_head.fit(\n",
    "        x=x_train, y=y_train, batch_size=batch_size, validation_data=(x_test, y_test), epochs=num_epochs,\n",
    "        callbacks=[model_checkpoint_callback, early_stopping]\n",
    "    )\n",
    "    # \n",
    "    # encoder = load_model('model_best_encoder_3.keras', custom_objects={\n",
    "    #     'SupervisedContrastiveLoss': SupervisedContrastiveLoss\n",
    "    # }).layers[1]\n",
    "    return encoder"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "189f94dad9b5e850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T19:58:00.217617Z",
     "start_time": "2024-08-14T19:57:57.752483Z"
    }
   },
   "source": [
    "from src.Instrument.Contrastive import SupervisedContrastiveLoss, create_classifier, create_encoder, \\\n",
    "    add_projection_head, learning_rate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def train_contrastive_model(x, y, num_classes):\n",
    "    \"\"\" Train Siamese network using contrastive learning \"\"\"\n",
    "    n_splits = 5\n",
    "    if y.ndim > 1:\n",
    "        y_labels = np.argmax(y, axis=1)\n",
    "    else:\n",
    "        y_labels = y\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "histories = []\n",
    "\n",
    "    for fold_no, (train_index, test_index) in enumerate(skf.split(x, y_labels), start=1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        # y_train, y_test = y[train_index], y[test_index]\n",
    "        y_train, y_test = y_labels[train_index], y_labels[test_index]\n",
    "        input_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
    "        model_path = f'model_best_classifier_{fold_no}.keras'\n",
    "        model_callback = ModelCheckpoint(\n",
    "            filepath=model_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        num_epochs = 100\n",
    "        batch_size = 12\n",
    "\n",
    "        encoder = get_encoder(x_train, y_train, x_test, y_test, batch_size, num_epochs, fold_no, input_shape,\n",
    "                              early_stopping)\n",
    "\n",
    "        classifier = create_classifier(encoder, num_classes, input_shape, trainable=False)\n",
    "\n",
    "        classifier.summary()\n",
    "\n",
    "        history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "                                 validation_data=(x_test, y_test), callbacks=[model_callback, early_stopping])\n",
    "\n",
    "        accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "        print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "        histories.append(history)\n",
    "        fold_no += 1\n",
    "\n",
    "    return histories\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\PycharmProjects\\Thesis\\.venv\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "G:\\PycharmProjects\\Thesis\\.venv\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-14T19:58:00.220616Z"
    }
   },
   "cell_type": "code",
   "source": "histories = train_contrastive_model(x, y, len(classes))",
   "id": "65350fb27de740ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 216, 64, 1)]      0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 256)               3524544   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,557,440\n",
      "Trainable params: 3,555,520\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1366/2880 [=============>................] - ETA: 1:41 - loss: 1.4607"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
